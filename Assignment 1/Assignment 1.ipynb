{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50652b8d",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d3f425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mysel\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mysel\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=aa9b8943d6189aa9fb856692e474f4bf093ecf43746e6c4cfbadc62144c0d84b\n",
      "  Stored in directory: c:\\users\\mysel\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Requirement already satisfied: requests in c:\\users\\mysel\\anaconda3\\lib\\site-packages (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\mysel\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mysel\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mysel\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mysel\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 1 :Write a python program to display all the header tags from wikipedia.org and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7b9ad91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f4e82419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome to Wikipedia',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "header = soup.find_all('span', class_=\"mw-headline\")\n",
    "heading = []\n",
    "for head in header:\n",
    "    heading.append(head.get_text().strip())\n",
    "heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 2: Write a python program to display IMDB’s Top rated 50 movies’ data (i.e. name, rating, year of release)\n",
    "and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19afd44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f832e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page2 = requests.get('https://www.imdb.com/list/ls055386972/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c37f16f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Godfather',\n",
       " \"Schindler's List\",\n",
       " '12 Angry Men',\n",
       " 'La vita è bella',\n",
       " 'Il buono, il brutto, il cattivo',\n",
       " 'The Shawshank Redemption',\n",
       " 'The Pursuit of Happyness',\n",
       " 'Shichinin no samurai',\n",
       " 'The Intouchables',\n",
       " 'Central do Brasil',\n",
       " 'Requiem for a Dream',\n",
       " 'A Beautiful Mind',\n",
       " \"Hachi: A Dog's Tale\",\n",
       " 'Taken',\n",
       " 'Yeopgijeogin geunyeo',\n",
       " 'Amores perros',\n",
       " 'The Shining',\n",
       " 'Apocalypto',\n",
       " 'Gladiator',\n",
       " 'Cast Away',\n",
       " 'The Dark Knight',\n",
       " 'The Pianist',\n",
       " 'Titanic',\n",
       " 'Bin-jip',\n",
       " 'Braveheart',\n",
       " \"It's a Wonderful Life\",\n",
       " 'Bom yeoreum gaeul gyeoul geurigo bom',\n",
       " 'Alien',\n",
       " 'Salinui chueok',\n",
       " 'Vozvrashchenie',\n",
       " 'Ang-ma-reul bo-at-da',\n",
       " 'Bacheha-Ye aseman',\n",
       " 'Jodaeiye Nader az Simin',\n",
       " 'The Sixth Sense',\n",
       " 'Nae meorisokui jiwoogae',\n",
       " 'Okuribito',\n",
       " 'Wo de fu qin mu qin',\n",
       " 'Saving Private Ryan',\n",
       " 'The Bridge on the River Kwai',\n",
       " 'Ben-Hur',\n",
       " 'The Exorcist',\n",
       " 'El secreto de sus ojos',\n",
       " 'Léon',\n",
       " 'The Green Mile',\n",
       " 'Gran Torino',\n",
       " 'Kill Bill: Vol. 1',\n",
       " 'Jurassic Park',\n",
       " 'Terminator 2: Judgment Day',\n",
       " 'Back to the Future',\n",
       " 'Finding Nemo']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2 = BeautifulSoup(page2.content)\n",
    "soup2 = BeautifulSoup(page2.content, \"html.parser\")\n",
    "name = soup2.find_all('h3', class_=\"lister-item-header\")\n",
    "movie_name = []\n",
    "for names in name:\n",
    "    movie_name.append(names.get_text().split('\\n')[2])\n",
    "movie_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "93c09688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1972)',\n",
       " '(1993)',\n",
       " '(1957)',\n",
       " '(1997)',\n",
       " '(1966)',\n",
       " '(1994)',\n",
       " '(2006)',\n",
       " '(1954)',\n",
       " '(2011)',\n",
       " '(1998)',\n",
       " '(2000)',\n",
       " '(2001)',\n",
       " '(2009)',\n",
       " '(I) (2008)',\n",
       " '(2001)',\n",
       " '(2000)',\n",
       " '(1980)',\n",
       " '(2006)',\n",
       " '(2000)',\n",
       " '(2000)',\n",
       " '(2008)',\n",
       " '(2002)',\n",
       " '(1997)',\n",
       " '(2004)',\n",
       " '(1995)',\n",
       " '(1946)',\n",
       " '(2003)',\n",
       " '(1979)',\n",
       " '(2003)',\n",
       " '(2003)',\n",
       " '(2010)',\n",
       " '(1997)',\n",
       " '(2011)',\n",
       " '(1999)',\n",
       " '(2004)',\n",
       " '(2008)',\n",
       " '(1999)',\n",
       " '(1998)',\n",
       " '(1957)',\n",
       " '(1959)',\n",
       " '(1973)',\n",
       " '(2009)',\n",
       " '(1994)',\n",
       " '(1999)',\n",
       " '(2008)',\n",
       " '(2003)',\n",
       " '(1993)',\n",
       " '(1991)',\n",
       " '(1985)',\n",
       " '(2003)']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = soup2.find_all('span', class_=\"lister-item-year text-muted unbold\")\n",
    "top_movie_year = []\n",
    "for years in year:\n",
    "    top_movie_year.append(years.get_text().strip())\n",
    "top_movie_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "47c38e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '9',\n",
       " '9',\n",
       " '8.6',\n",
       " '8.8',\n",
       " '9.3',\n",
       " '8',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '7.8',\n",
       " '8',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '7.8',\n",
       " '8.5',\n",
       " '7.8',\n",
       " '9',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '8.4',\n",
       " '8.6',\n",
       " '8',\n",
       " '8.5',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '7.8',\n",
       " '8.2',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8',\n",
       " '7.8',\n",
       " '8.6',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.2']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = soup2.find_all('div', class_=\"ipl-rating-star small\")\n",
    "top_rating = []\n",
    "for rate in rating:\n",
    "    top_rating.append(rate.get_text().strip())\n",
    "top_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "900f87c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>release year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>9</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La vita è bella</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Il buono, il brutto, il cattivo</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1966)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        movie name Rating release year\n",
       "0                    The Godfather    9.2       (1972)\n",
       "1                 Schindler's List      9       (1993)\n",
       "2                     12 Angry Men      9       (1957)\n",
       "3                  La vita è bella    8.6       (1997)\n",
       "4  Il buono, il brutto, il cattivo    8.8       (1966)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data['movie name'] = movie_name\n",
    "data['Rating'] = top_rating\n",
    "data['release year'] = top_movie_year\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82885fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 3: Write a python program to display IMDB’s Top rated 50 Indian movies’ data (i.e. name, rating, year of\n",
    "release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c8305c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page3 = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "page3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "39049eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['      Ramayana: The Legend of Prince Rama',\n",
       " '      Rocketry: The Nambi Effect',\n",
       " '      Nayakan',\n",
       " '      Gol Maal',\n",
       " '      Anbe Sivam',\n",
       " '      777 Charlie',\n",
       " '      Jai Bhim',\n",
       " '      Pariyerum Perumal',\n",
       " '      3 Idiots',\n",
       " '      Manichitrathazhu',\n",
       " '      Apur Sansar',\n",
       " '      #Home',\n",
       " '      Soorarai Pottru',\n",
       " '      Black Friday',\n",
       " '      Kumbalangi Nights',\n",
       " '      C/o Kancharapalem',\n",
       " '      Taare Zameen Par',\n",
       " '      Kireedam',\n",
       " '      Dangal',\n",
       " '      Kaithi',\n",
       " '      Jersey',\n",
       " '      96',\n",
       " '      Maya Bazaar',\n",
       " '      Natsamrat',\n",
       " '      Asuran',\n",
       " '      Drishyam 2',\n",
       " '      Sita Ramam',\n",
       " '      Thevar Magan',\n",
       " '      Visaaranai',\n",
       " '      Sarpatta Parambarai',\n",
       " '      Thalapathi',\n",
       " '      Pather Panchali',\n",
       " '      Nadodikkattu',\n",
       " '      Drishyam',\n",
       " '      Jaane Bhi Do Yaaro',\n",
       " '      Thani Oruvan',\n",
       " '      Sardar Udham',\n",
       " '      Aparajito',\n",
       " '      Vada Chennai',\n",
       " '      Khosla Ka Ghosla!',\n",
       " '      Anniyan',\n",
       " '      Ratsasan',\n",
       " '      Chupke Chupke',\n",
       " '      Gangs of Wasseypur',\n",
       " '      Peranbu',\n",
       " '      Drishyam',\n",
       " '      Mahanati',\n",
       " '      Bangalore Days',\n",
       " '      Satya',\n",
       " '      Agent Sai Srinivasa Athreya',\n",
       " '      Premam',\n",
       " '      Devasuram',\n",
       " '      Super Deluxe',\n",
       " '      Bhaag Milkha Bhaag',\n",
       " '      Tumbbad',\n",
       " '      Andhadhun',\n",
       " '      Vikram Vedha',\n",
       " '      Guide',\n",
       " '      Chithram',\n",
       " '      Zindagi Na Milegi Dobara',\n",
       " '      Kannathil Muthamittal',\n",
       " '      Sairat',\n",
       " '      Vikram',\n",
       " '      Shahid',\n",
       " '      Chhichhore',\n",
       " '      Iruvar',\n",
       " '      Paan Singh Tomar',\n",
       " '      Aruvi',\n",
       " '      Swades: We, the People',\n",
       " '      Munna Bhai M.B.B.S.',\n",
       " '      Spadikam',\n",
       " '      Chak De! India',\n",
       " '      Uri: The Surgical Strike',\n",
       " '      Pyaasa',\n",
       " '      Mudhalvan',\n",
       " '      Black',\n",
       " '      Jo Jeeta Wohi Sikandar',\n",
       " '      Drishyam 2',\n",
       " '      Hera Pheri',\n",
       " '      Papanasam',\n",
       " '      Lagaan: Once Upon a Time in India',\n",
       " '      Pudhu Pettai',\n",
       " '      Dhuruvangal Pathinaaru',\n",
       " '      PK',\n",
       " '      Mandela',\n",
       " '      Queen',\n",
       " '      Article 15',\n",
       " '      Talvar',\n",
       " '      Soodhu Kavvum',\n",
       " '      OMG: Oh My God!',\n",
       " '      Sarfarosh',\n",
       " '      Sholay',\n",
       " '      Udaan',\n",
       " '      Barfi!',\n",
       " '      Jigarthanda',\n",
       " '      The Legend of Bhagat Singh',\n",
       " '      Kaakkaa Muttai',\n",
       " '      Ustad Hotel',\n",
       " '      Theeran Adhigaaram Ondru',\n",
       " '      Baahubali 2: The Conclusion',\n",
       " '      Rang De Basanti',\n",
       " '      Angoor',\n",
       " '      Jana Gana Mana',\n",
       " '      Kahaani',\n",
       " '      Masaan',\n",
       " '      Maheshinte Prathikaaram',\n",
       " '      A Wednesday',\n",
       " '      Dil Chahta Hai',\n",
       " '      Virumandi',\n",
       " '      Baasha',\n",
       " '      Shershaah',\n",
       " '      Lage Raho Munna Bhai',\n",
       " '      Kantara',\n",
       " '      Iqbal',\n",
       " '      Pink',\n",
       " '      Roja',\n",
       " '      Pithamagan',\n",
       " '      Anand',\n",
       " '      Nil Battey Sannata',\n",
       " '      Kaun Pravin Tambe?',\n",
       " '      Lucia',\n",
       " '      Charulata',\n",
       " '      Bajrangi Bhaijaan',\n",
       " '      Omkara',\n",
       " '      Oru Vadakkan Veeragatha',\n",
       " '      Bommarillu',\n",
       " '      Section 375',\n",
       " '      Alai Payuthey',\n",
       " '      Bombay',\n",
       " '      K.G.F: Chapter 1',\n",
       " '      Rangasthalam',\n",
       " '      Indian',\n",
       " '      Dilwale Dulhania Le Jayenge',\n",
       " '      Haider',\n",
       " '      Mughal-E-Azam',\n",
       " '      Athadu',\n",
       " '      The Great Indian Kitchen',\n",
       " '      Andaz Apna Apna',\n",
       " '      Special Chabbis',\n",
       " '      Maqbool',\n",
       " '      Vaaranam Aayiram',\n",
       " '      Thadam',\n",
       " '      Padayappa',\n",
       " '      Gulaal',\n",
       " '      Maanaadu',\n",
       " '      K.G.F: Chapter 2',\n",
       " '      Pelli Choopulu',\n",
       " '      Ulidavaru Kandanthe',\n",
       " '      Deewaar',\n",
       " '      Company',\n",
       " '      Vaastav: The Reality',\n",
       " '      Ugly',\n",
       " '      Badhaai ho',\n",
       " '      Naduvula Konjam Pakkatha Kaanom',\n",
       " '      Padosan',\n",
       " '      Gully Boy',\n",
       " '      Kshanam',\n",
       " '      Evaru',\n",
       " '      Aadukalam',\n",
       " '      My Name Is Khan',\n",
       " '      Nayattu',\n",
       " '      Dev.D',\n",
       " '      Maanagaram',\n",
       " '      Major',\n",
       " '      Thondimuthalum Dhriksakshiyum',\n",
       " '      Pranchiyettan and the Saint',\n",
       " '      Kal Ho Naa Ho',\n",
       " '      Garuda Gamana Vrishabha Vahana',\n",
       " '      Baishe Srabon',\n",
       " '      Take Off',\n",
       " '      Jab We Met',\n",
       " '      Manjhi: The Mountain Man',\n",
       " '      Ayyappanum Koshiyum',\n",
       " '      Ship of Theseus',\n",
       " '      Mukkabaaz',\n",
       " '      Charlie',\n",
       " '      Border',\n",
       " '      Deiva Thirumagal',\n",
       " '      Vedam',\n",
       " '      Dil Bechara',\n",
       " '      M.S. Dhoni: The Untold Story',\n",
       " '      Bãhubali: The Beginning',\n",
       " '      Salaam Bombay!',\n",
       " '      Arjun Reddy',\n",
       " '      Padman',\n",
       " '      Karnan',\n",
       " '      Ankhon Dekhi',\n",
       " '      Baby',\n",
       " '      Love Today',\n",
       " '      Jalsaghar',\n",
       " '      Kirik Party',\n",
       " '      Vinnaithaandi Varuvaayaa',\n",
       " '      Super 30',\n",
       " '      The Tashkent Files',\n",
       " '      Malik',\n",
       " '      Hindi Medium',\n",
       " '      Pizza',\n",
       " '      Android Kunjappan Version 5.25',\n",
       " '      Hridayam',\n",
       " '      English Vinglish',\n",
       " '      Lakshya',\n",
       " '      Johnny Gaddaar',\n",
       " '      Memories',\n",
       " '      Dor',\n",
       " '      Hey Ram',\n",
       " '      Airlift',\n",
       " '      Joseph',\n",
       " '      RRR (Rise Roar Revolt)',\n",
       " '      Anjaam Pathiraa',\n",
       " '      Kaakha..Kaakha: The Police',\n",
       " '      Gangaajal',\n",
       " '      Okkadu',\n",
       " '      Pokiri',\n",
       " '      Thuppakki',\n",
       " '      The Lunchbox',\n",
       " '      Vettaiyaadu Vilaiyaadu',\n",
       " '      Ab Tak Chhappan',\n",
       " '      Mumbai Police',\n",
       " '      Ghilli',\n",
       " '      Manam',\n",
       " '      Unnaipol Oruvan',\n",
       " '      RangiTaranga',\n",
       " '      Veer-Zaara',\n",
       " '      Angamaly Diaries',\n",
       " '      Vicky Donor',\n",
       " '      Kaththi',\n",
       " '      Oopiri',\n",
       " '      Mother India',\n",
       " '      Secret Superstar',\n",
       " '      Stanley Ka Dabba',\n",
       " '      Thulladha Manamum Thullum',\n",
       " '      Nayak: The Real Hero',\n",
       " '      Rock On!!',\n",
       " '      Mr. India',\n",
       " '      Mimi',\n",
       " '      Udta Punjab',\n",
       " '      Sonchiriya',\n",
       " '      Oru CBI Diary Kurippu',\n",
       " '      Badla',\n",
       " '      Aayirathil Oruvan',\n",
       " '      Happy Days',\n",
       " '      Dasvidaniya',\n",
       " '      Raazi',\n",
       " '      Dia',\n",
       " '      Kai po che!',\n",
       " '      Poove Unakkaga',\n",
       " '      Minnal Murali',\n",
       " '      Thiruchitrambalam',\n",
       " '      Goodachari',\n",
       " '      Joji']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup3 = BeautifulSoup(page3.content)\n",
    "soup3 = BeautifulSoup(page3.content, \"html.parser\")\n",
    "name3 = soup3.find_all('td', class_=\"titleColumn\")\n",
    "movie_name3 = []\n",
    "for names3 in name3:\n",
    "    movie_name3.append(names3.get_text().split('\\n')[2])\n",
    "movie_name3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6136622a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8.5',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.6']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating3 = soup3.find_all('td', class_=\"ratingColumn imdbRating\")\n",
    "top_rating3 = []\n",
    "for rate3 in rating3:\n",
    "    top_rating3.append(rate3.get_text().strip())\n",
    "top_rating3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "62e1544f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1993)',\n",
       " '(2022)',\n",
       " '(1987)',\n",
       " '(1979)',\n",
       " '(2003)',\n",
       " '(2022)',\n",
       " '(2021)',\n",
       " '(2018)',\n",
       " '(2009)',\n",
       " '(1993)',\n",
       " '(1959)',\n",
       " '(2021)',\n",
       " '(2020)',\n",
       " '(2004)',\n",
       " '(2019)',\n",
       " '(2018)',\n",
       " '(2007)',\n",
       " '(1989)',\n",
       " '(2016)',\n",
       " '(2019)',\n",
       " '(2019)',\n",
       " '(2018)',\n",
       " '(1957)',\n",
       " '(2016)',\n",
       " '(2019)',\n",
       " '(2021)',\n",
       " '(2022)',\n",
       " '(1992)',\n",
       " '(2015)',\n",
       " '(2021)',\n",
       " '(1991)',\n",
       " '(1955)',\n",
       " '(1987)',\n",
       " '(2013)',\n",
       " '(1983)',\n",
       " '(2015)',\n",
       " '(2021)',\n",
       " '(1956)',\n",
       " '(2018)',\n",
       " '(2006)',\n",
       " '(2005)',\n",
       " '(2018)',\n",
       " '(1975)',\n",
       " '(2012)',\n",
       " '(2018)',\n",
       " '(2015)',\n",
       " '(2018)',\n",
       " '(2014)',\n",
       " '(1998)',\n",
       " '(2019)',\n",
       " '(2015)',\n",
       " '(1993)',\n",
       " '(2019)',\n",
       " '(2013)',\n",
       " '(2018)',\n",
       " '(2018)',\n",
       " '(2017)',\n",
       " '(1965)',\n",
       " '(1988)',\n",
       " '(2011)',\n",
       " '(2002)',\n",
       " '(2016)',\n",
       " '(2022)',\n",
       " '(2012)',\n",
       " '(2019)',\n",
       " '(1997)',\n",
       " '(2012)',\n",
       " '(2016)',\n",
       " '(2004)',\n",
       " '(2003)',\n",
       " '(1995)',\n",
       " '(2007)',\n",
       " '(2019)',\n",
       " '(1957)',\n",
       " '(1999)',\n",
       " '(2005)',\n",
       " '(1992)',\n",
       " '(2022)',\n",
       " '(2000)',\n",
       " '(2015)',\n",
       " '(2001)',\n",
       " '(2006)',\n",
       " '(2016)',\n",
       " '(2014)',\n",
       " '(2021)',\n",
       " '(2013)',\n",
       " '(2019)',\n",
       " '(2015)',\n",
       " '(2013)',\n",
       " '(2012)',\n",
       " '(1999)',\n",
       " '(1975)',\n",
       " '(2010)',\n",
       " '(2012)',\n",
       " '(2014)',\n",
       " '(2002)',\n",
       " '(2014)',\n",
       " '(2012)',\n",
       " '(2017)',\n",
       " '(2017)',\n",
       " '(2006)',\n",
       " '(1982)',\n",
       " '(2022)',\n",
       " '(2012)',\n",
       " '(2015)',\n",
       " '(2016)',\n",
       " '(2008)',\n",
       " '(2001)',\n",
       " '(2004)',\n",
       " '(1995)',\n",
       " '(2021)',\n",
       " '(2006)',\n",
       " '(2022)',\n",
       " '(2005)',\n",
       " '(2016)',\n",
       " '(1992)',\n",
       " '(2003)',\n",
       " '(1971)',\n",
       " '(2015)',\n",
       " '(2022)',\n",
       " '(2013)',\n",
       " '(1964)',\n",
       " '(2015)',\n",
       " '(2006)',\n",
       " '(1989)',\n",
       " '(2006)',\n",
       " '(2019)',\n",
       " '(2000)',\n",
       " '(1995)',\n",
       " '(2018)',\n",
       " '(2018)',\n",
       " '(1996)',\n",
       " '(1995)',\n",
       " '(2014)',\n",
       " '(1960)',\n",
       " '(2005)',\n",
       " '(2021)',\n",
       " '(1994)',\n",
       " '(2013)',\n",
       " '(2003)',\n",
       " '(2008)',\n",
       " '(2019)',\n",
       " '(1999)',\n",
       " '(2009)',\n",
       " '(2021)',\n",
       " '(2022)',\n",
       " '(2016)',\n",
       " '(2014)',\n",
       " '(1975)',\n",
       " '(2002)',\n",
       " '(1999)',\n",
       " '(2013)',\n",
       " '(2018)',\n",
       " '(2012)',\n",
       " '(1968)',\n",
       " '(2019)',\n",
       " '(2016)',\n",
       " '(2019)',\n",
       " '(2011)',\n",
       " '(2010)',\n",
       " '(2021)',\n",
       " '(2009)',\n",
       " '(2017)',\n",
       " '(2022)',\n",
       " '(2017)',\n",
       " '(2010)',\n",
       " '(2003)',\n",
       " '(2021)',\n",
       " '(2011)',\n",
       " '(2017)',\n",
       " '(2007)',\n",
       " '(2015)',\n",
       " '(2020)',\n",
       " '(2012)',\n",
       " '(2017)',\n",
       " '(2015)',\n",
       " '(1997)',\n",
       " '(2011)',\n",
       " '(2010)',\n",
       " '(2020)',\n",
       " '(2016)',\n",
       " '(2015)',\n",
       " '(1988)',\n",
       " '(2017)',\n",
       " '(2018)',\n",
       " '(2021)',\n",
       " '(2013)',\n",
       " '(2015)',\n",
       " '(2022)',\n",
       " '(1958)',\n",
       " '(2016)',\n",
       " '(2010)',\n",
       " '(2019)',\n",
       " '(2019)',\n",
       " '(2021)',\n",
       " '(2017)',\n",
       " '(2012)',\n",
       " '(2019)',\n",
       " '(2022)',\n",
       " '(2012)',\n",
       " '(2004)',\n",
       " '(2007)',\n",
       " '(2013)',\n",
       " '(2006)',\n",
       " '(2000)',\n",
       " '(2016)',\n",
       " '(2018)',\n",
       " '(2022)',\n",
       " '(2020)',\n",
       " '(2003)',\n",
       " '(2003)',\n",
       " '(2003)',\n",
       " '(2006)',\n",
       " '(2012)',\n",
       " '(2013)',\n",
       " '(2006)',\n",
       " '(2004)',\n",
       " '(2013)',\n",
       " '(2004)',\n",
       " '(2014)',\n",
       " '(2009)',\n",
       " '(2015)',\n",
       " '(2004)',\n",
       " '(2017)',\n",
       " '(2012)',\n",
       " '(2014)',\n",
       " '(2016)',\n",
       " '(1957)',\n",
       " '(2017)',\n",
       " '(2011)',\n",
       " '(1999)',\n",
       " '(2001)',\n",
       " '(2008)',\n",
       " '(1987)',\n",
       " '(2021)',\n",
       " '(2016)',\n",
       " '(2019)',\n",
       " '(1988)',\n",
       " '(2019)',\n",
       " '(2010)',\n",
       " '(2007)',\n",
       " '(2008)',\n",
       " '(2018)',\n",
       " '(2020)',\n",
       " '(2013)',\n",
       " '(1996)',\n",
       " '(2021)',\n",
       " '(2022)',\n",
       " '(2018)',\n",
       " '(2021)']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year3 = soup3.find_all('td', class_=\"titleColumn\")\n",
    "top_movie_year3 = []\n",
    "for years3 in year3:\n",
    "    top_movie_year3.append(years3.get_text().split('\\n')[3])\n",
    "top_movie_year3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "397b1c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>release year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ramayana: The Legend of Prince Rama</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rocketry: The Nambi Effect</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gol Maal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  movie name Rating release year\n",
       "0        Ramayana: The Legend of Prince Rama    8.5       (1993)\n",
       "1                 Rocketry: The Nambi Effect    8.4       (2022)\n",
       "2                                    Nayakan    8.4       (1987)\n",
       "3                                   Gol Maal    8.4       (1979)\n",
       "4                                 Anbe Sivam    8.4       (2003)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3 = pd.DataFrame()\n",
    "data3['movie name'] = movie_name3\n",
    "data3['Rating'] = top_rating3\n",
    "data3['release year'] = top_movie_year3\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66559175",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUestion 4: Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aa104098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page4 = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "page4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cbee02ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shri Ram Nath Kovind ',\n",
       " 'Shri Pranab Mukherjee ',\n",
       " 'Smt Pratibha Devisingh Patil ',\n",
       " 'DR. A.P.J. Abdul Kalam ',\n",
       " 'Shri K. R. Narayanan ',\n",
       " 'Dr Shankar Dayal Sharma ',\n",
       " 'Shri R Venkataraman ',\n",
       " 'Giani Zail Singh ',\n",
       " 'Shri Neelam Sanjiva Reddy ',\n",
       " 'Dr. Fakhruddin Ali Ahmed ',\n",
       " 'Shri Varahagiri Venkata Giri ',\n",
       " 'Dr. Zakir Husain ',\n",
       " 'Dr. Sarvepalli Radhakrishnan ',\n",
       " 'Dr. Rajendra Prasad ']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup4 = BeautifulSoup(page4.content)\n",
    "soup4 = BeautifulSoup(page4.content, \"html.parser\")\n",
    "name4 = soup4.find_all('div', class_=\"presidentListing\")\n",
    "president_name = []\n",
    "for names4 in name4:\n",
    "    president_name.append(names4.get_text().split('(')[0].split('\\n')[1])\n",
    "president_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "102e3f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['birth - 1945',\n",
       " '1935-2020',\n",
       " 'birth - 1934',\n",
       " '1931-2015',\n",
       " '1920 - 2005',\n",
       " '1918-1999',\n",
       " '1910-2009',\n",
       " '1916-1994',\n",
       " '1913-1996',\n",
       " '1905-1977',\n",
       " '1894-1980',\n",
       " '1897-1969',\n",
       " '1888-1975',\n",
       " '1884-1963']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name4\n",
    "term=[]\n",
    "for term4 in name4:\n",
    "    term.append(term4.get_text().split('(')[1].split(')')[0])\n",
    "term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dbad4755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term of office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>birth - 1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>1935-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>birth - 1934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>1931-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>1920 - 2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name Term of office\n",
       "0          Shri Ram Nath Kovind    birth - 1945\n",
       "1         Shri Pranab Mukherjee       1935-2020\n",
       "2  Smt Pratibha Devisingh Patil    birth - 1934\n",
       "3        DR. A.P.J. Abdul Kalam       1931-2015\n",
       "4          Shri K. R. Narayanan     1920 - 2005"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4 = pd.DataFrame()\n",
    "data4['Name'] = president_name\n",
    "data4['Term of office'] = term\n",
    "data4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b59ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 5: Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data framea) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "c) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4e86a553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page5 = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "679c6205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India',\n",
       " 'Australia',\n",
       " 'New Zealand',\n",
       " 'England',\n",
       " 'Pakistan',\n",
       " 'South Africa',\n",
       " 'Bangladesh',\n",
       " 'Sri Lanka',\n",
       " 'Afghanistan']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup5 = BeautifulSoup(page5.content)\n",
    "soup5 = BeautifulSoup(page5.content, \"html.parser\")\n",
    "name5 = soup5.find_all('span', class_=\"u-hide-phablet\")\n",
    "team_men1 = []\n",
    "for names5 in name5:\n",
    "    team_men1.append(names5.get_text())\n",
    "team_men = team_men1[0:9]\n",
    "team_men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "334e712d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['44']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = soup5.find_all('td', class_=\"rankings-block__banner--matches\")\n",
    "match_ind = []\n",
    "for mat in match:\n",
    "    match_ind.append(mat.get_text())\n",
    "match_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ad38a9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['32', '29', '33', '25', '27', '33', '34', '20', '41']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match5 = soup5.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "match55 = []\n",
    "for mat5 in match5:\n",
    "    match55.append(mat5.get_text())\n",
    "match_play = match55[0:17:2]\n",
    "match_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a02a350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['44', '32', '29', '33', '25', '27', '33', '34', '20', '41']\n"
     ]
    }
   ],
   "source": [
    "match_ind.extend(match_play)\n",
    "print(match_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "6d7b04a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,010']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point5 = soup5.find_all('td', class_=\"rankings-block__banner--points\")\n",
    "points = []\n",
    "for point in point5:\n",
    "    points.append(point.get_text())\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e5f8f55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3,572',\n",
       " '3,229',\n",
       " '3,656',\n",
       " '2,649',\n",
       " '2,775',\n",
       " '3,129',\n",
       " '2,976',\n",
       " '1,419',\n",
       " '2,902']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oint5 = soup5.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "oints = []\n",
    "for oint in oint5:\n",
    "    oints.append(oint.get_text())\n",
    "point_other= oints[1:18:2]\n",
    "point_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c0f836e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5,010', '3,572', '3,229', '3,656', '2,649', '2,775', '3,129', '2,976', '1,419', '2,902']\n"
     ]
    }
   ],
   "source": [
    "points.extend(point_other)\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ed948fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,010',\n",
       " '3,572',\n",
       " '3,229',\n",
       " '3,656',\n",
       " '2,649',\n",
       " '2,775',\n",
       " '3,129',\n",
       " '2,976',\n",
       " '1,419',\n",
       " '2,902']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "be901641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                            114']"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating5 = soup5.find_all('td', class_=\"rankings-block__banner--rating u-text-right\")\n",
    "ratings = []\n",
    "for rate in rating5:\n",
    "    ratings.append(rate.get_text().split('\\n')[1])\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "5d96ef4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['112', '111', '111', '106', '103', '95', '88', '71', '71']"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating5_other = soup5.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "ratings_other = []\n",
    "for rate_other in rating5_other:\n",
    "    ratings_other.append(rate_other.get_text())\n",
    "rating_others= ratings_other[0:9]\n",
    "rating_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ab6c59f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['                            114', '112', '111', '111', '106', '103', '95', '88', '71', '71']\n"
     ]
    }
   ],
   "source": [
    "ratings.extend(rating_others)\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4000f97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                            114',\n",
       " '112',\n",
       " '111',\n",
       " '111',\n",
       " '106',\n",
       " '103',\n",
       " '95',\n",
       " '88',\n",
       " '71',\n",
       " '71']"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "1ef2c61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       matches\n",
       "0        India\n",
       "1    Australia\n",
       "2  New Zealand\n",
       "3      England\n",
       "4     Pakistan"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5 = pd.DataFrame()\n",
    "data5['matches'] = team_men\n",
    "\n",
    "data5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36091c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Top 10 ODI batsman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "85fe2973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam']"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page5bat = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "soup5bat = BeautifulSoup(page5bat.content)\n",
    "soup5bat = BeautifulSoup(page5bat.content, \"html.parser\")\n",
    "name5bat = soup5bat.find_all('div', class_=\"rankings-block__banner--name-large\")\n",
    "team_men1bat = []\n",
    "for names5bat in name5bat:\n",
    "    team_men1bat.append(names5bat.get_text())\n",
    "team_men1bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "dd8d838b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rassie van der Dussen',\n",
       " 'David Warner',\n",
       " 'Quinton de Kock',\n",
       " 'Imam-ul-Haq',\n",
       " 'Shubman Gill',\n",
       " 'Virat Kohli',\n",
       " 'Steve Smith',\n",
       " 'Rohit Sharma',\n",
       " 'Kane Williamson']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name5bat_other = soup5bat.find_all('td', class_=\"table-body__cell rankings-table__name name\")\n",
    "team_men1bat_other = []\n",
    "for names5bat_other in name5bat_other:\n",
    "    team_men1bat_other.append(names5bat_other.get_text().split('\\n')[1])\n",
    "odi_bat= team_men1bat_other[0:9]\n",
    "odi_bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "22112b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam',\n",
       " 'Rassie van der Dussen',\n",
       " 'David Warner',\n",
       " 'Quinton de Kock',\n",
       " 'Imam-ul-Haq',\n",
       " 'Shubman Gill',\n",
       " 'Virat Kohli',\n",
       " 'Steve Smith',\n",
       " 'Rohit Sharma',\n",
       " 'Kane Williamson']"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_men1bat.extend(odi_bat)\n",
    "odi_top = team_men1bat[0:10]\n",
    "odi_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "cf468558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAK']"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name5team = soup5bat.find_all('div', class_=\"rankings-block__banner--nationality\")\n",
    "team_men1team = []\n",
    "for names5team in name5team:\n",
    "    team_men1team.append(names5team.get_text().split('\\n')[2])\n",
    "team_men1team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "71c6115c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SA', 'AUS', 'SA', 'PAK', 'IND', 'IND', 'AUS', 'IND', 'NZ']"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name5team_other = soup5bat.find_all('span', class_=\"table-body__logo-text\")\n",
    "team_men1team_other = []\n",
    "for names5team_other in name5team_other:\n",
    "    team_men1team_other.append(names5team_other.get_text())\n",
    "team_other= team_men1team_other[0:9]\n",
    "team_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e0b09aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAK', 'SA', 'AUS', 'SA', 'PAK', 'IND', 'IND', 'AUS', 'IND', 'NZ']"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_men1team.extend(team_other)\n",
    "team_other = team_men1team[0:10]\n",
    "team_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d73e9bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['887']"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name5rate = soup5bat.find_all('div', class_=\"rankings-block__banner--rating\")\n",
    "team_men1rate = []\n",
    "for names5rate in name5rate:\n",
    "    team_men1rate.append(names5rate.get_text())\n",
    "team_men1rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "da313b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['787', '747', '743', '740', '734', '727', '719', '719', '700']"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name5rate = soup5bat.find_all('td', class_=\"table-body__cell rating\")\n",
    "team_men1rate = []\n",
    "for names5rate in name5rate:\n",
    "    team_men1rate.append(names5rate.get_text())\n",
    "team_rate= team_men1rate[0:9]\n",
    "team_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "08e5366b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['787', '747', '743', '740', '734', '727', '719', '719', '700', '699']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_men1rate.extend(team_rate)\n",
    "team_other_rate = team_men1rate[0:10]\n",
    "team_other_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "a008576e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>team</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name team rating\n",
       "0             Babar Azam  PAK    787\n",
       "1  Rassie van der Dussen   SA    747\n",
       "2           David Warner  AUS    743\n",
       "3        Quinton de Kock   SA    740\n",
       "4            Imam-ul-Haq  PAK    734"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data55 = pd.DataFrame()\n",
    "data55['name'] = odi_top\n",
    "data55['team'] = team_other\n",
    "data55['rating'] = team_other_rate\n",
    "data55.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf69dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Top 10 ODI bowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "90fde295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mohammed Siraj']"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_bowler = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "soup_bowler = BeautifulSoup(page_bowler.content)\n",
    "soup_bowler = BeautifulSoup(page_bowler.content, \"html.parser\")\n",
    "name_bowler = soup_bowler.find_all('div', class_=\"rankings-block__banner--name-large\")\n",
    "team_bowler = []\n",
    "for names_bowler in name_bowler:\n",
    "    team_bowler.append(names_bowler.get_text())\n",
    "team_bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "84531fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Josh Hazlewood',\n",
       " 'Trent Boult',\n",
       " 'Mitchell Starc',\n",
       " 'Rashid Khan',\n",
       " 'Adam Zampa',\n",
       " 'Shakib Al Hasan',\n",
       " 'Shaheen Afridi',\n",
       " 'Mustafizur Rahman',\n",
       " 'Mujeeb Ur Rahman']"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_bowler_other = soup_bowler.find_all('td', class_=\"table-body__cell rankings-table__name name\")\n",
    "team_bowler_other = []\n",
    "for names_bowler_other in name_bowler_other:\n",
    "    team_bowler_other.append(names_bowler_other.get_text().split('\\n')[1])\n",
    "men_bowler = team_bowler_other[0:9]\n",
    "men_bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "0f78ab19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mohammed Siraj',\n",
       " 'Josh Hazlewood',\n",
       " 'Trent Boult',\n",
       " 'Mitchell Starc',\n",
       " 'Rashid Khan',\n",
       " 'Adam Zampa',\n",
       " 'Shakib Al Hasan',\n",
       " 'Shaheen Afridi',\n",
       " 'Mustafizur Rahman',\n",
       " 'Mujeeb Ur Rahman']"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_bowler.extend(men_bowler)\n",
    "team_bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "35c6958e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IND']"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_bowler = soup_bowler.find_all('div', class_=\"rankings-block__banner--nationality\")\n",
    "team_men_bowler = []\n",
    "for names_bowler in name_bowler:\n",
    "    team_men_bowler.append(names_bowler.get_text().split('\\n')[2])\n",
    "team_men_bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "2b13374e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUS', 'NZ', 'AUS', 'AFG', 'AUS', 'BAN', 'PAK', 'BAN', 'AFG']"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_bowler_other = soup_bowler.find_all('span', class_=\"table-body__logo-text\")\n",
    "team_men_bowler_other = []\n",
    "for names_bowler_other in name_bowler_other:\n",
    "    team_men_bowler_other.append(names_bowler_other.get_text())\n",
    "bowler=team_men_bowler_other[0:9]\n",
    "bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "a862072e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IND', 'AUS', 'NZ', 'AUS', 'AFG', 'AUS', 'BAN', 'PAK', 'BAN', 'AFG']"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_men_bowler.extend(bowler)\n",
    "team_men_bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "9b50bce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['729']"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_rating = soup_bowler.find_all('div', class_=\"rankings-block__banner--rating\")\n",
    "team_men_rating = []\n",
    "for names_rating in name_rating:\n",
    "    team_men_rating.append(names_rating.get_text())\n",
    "team_men_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "d36bfb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['727', '708', '665', '659', '655', '652', '641', '638', '637']"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_rating = soup_bowler.find_all('td', class_=\"table-body__cell rating\")\n",
    "team_men_rating = []\n",
    "for names_rating in name_rating:\n",
    "    team_men_rating.append(names_rating.get_text())\n",
    "bowler_rating=team_men_rating[0:9]\n",
    "bowler_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "f4dd7874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['727', '708', '665', '659', '655', '652', '641', '638', '637', '631']"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_men_rating.extend(bowler_rating)\n",
    "rating=team_men_rating[0:10]\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "55c99fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>team</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name team rating\n",
       "0  Mohammed Siraj  IND    727\n",
       "1  Josh Hazlewood  AUS    708\n",
       "2     Trent Boult   NZ    665\n",
       "3  Mitchell Starc  AUS    659\n",
       "4     Rashid Khan  AFG    655"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bowler = pd.DataFrame()\n",
    "data_bowler['name'] = team_bowler\n",
    "data_bowler['team'] = team_men_bowler\n",
    "data_bowler['rating'] = rating\n",
    "data_bowler.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08515953",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 6: Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data framea) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "110694cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page6 = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "page6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "6a3985cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'England',\n",
       " 'South Africa',\n",
       " 'India',\n",
       " 'New Zealand',\n",
       " 'West Indies',\n",
       " 'Bangladesh',\n",
       " 'Thailand',\n",
       " 'Pakistan',\n",
       " 'Sri Lanka']"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup6 = BeautifulSoup(page6.content)\n",
    "soup6 = BeautifulSoup(page6.content, \"html.parser\")\n",
    "name_wm = soup6.find_all('span', class_=\"u-hide-phablet\")\n",
    "team_wm = []\n",
    "for names_wm in name_wm:\n",
    "    team_wm.append(names_wm.get_text())\n",
    "women_team = team_wm[0:10]\n",
    "women_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "a34c85eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21']"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_wm_match = soup6.find_all('td', class_=\"rankings-block__banner--matches\")\n",
    "team_wm_match = []\n",
    "for names_wm_match in name_wm_match:\n",
    "    team_wm_match.append(names_wm_match.get_text())\n",
    "team_wm_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "08289813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['28', '26', '27', '25', '27', '13', '8', '27', '8']"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_wm_match1 = soup6.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "team_wm_match1 = []\n",
    "for names_wm_match1 in name_wm_match1:\n",
    "    team_wm_match1.append(names_wm_match1.get_text())\n",
    "women_team_match1 = team_wm_match1[0:18:2]\n",
    "women_team_match1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "ec1b1fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21', '28', '26', '27', '25', '27', '13', '8', '27', '8']"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_wm_match.extend(women_team_match1)\n",
    "team_wm_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "330d57c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3,342',\n",
       " '3,098',\n",
       " '2,820',\n",
       " '2,553',\n",
       " '2,535',\n",
       " '983',\n",
       " '572',\n",
       " '1,678',\n",
       " '353',\n",
       " '548']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_wm_match1 = soup6.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "team_wm_match1 = []\n",
    "for names_wm_match1 in name_wm_match1:\n",
    "    team_wm_match1.append(names_wm_match1.get_text())\n",
    "women_team_point = team_wm_match1[1:20:2]\n",
    "women_team_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "5f032926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['172\\n']"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_wm_rating = soup6.find_all('td', class_=\"rankings-block__banner--rating u-text-right\")\n",
    "team_wm_rating = []\n",
    "for names_wm_rating in name_wm_rating:\n",
    "    team_wm_rating.append(names_wm_rating.get_text().split(' ')[28])\n",
    "team_wm_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "4a4f6f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['119', '119', '104', '102', '94', '76', '72', '62', '44']"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_wm_rating_other = soup6.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "team_wm_rating_other = []\n",
    "for names_wm_rating_other in name_wm_rating_other:\n",
    "    team_wm_rating_other.append(names_wm_rating_other.get_text())\n",
    "rating_wm_other=team_wm_rating_other[0:9]\n",
    "rating_wm_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "acbaf44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['172\\n', '119', '119', '104', '102', '94', '76', '72', '62', '44']"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_wm_rating.extend(rating_wm_other)\n",
    "team_wm_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "af326a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>21</td>\n",
       "      <td>3,342</td>\n",
       "      <td>172\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>28</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>2,820</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>27</td>\n",
       "      <td>2,553</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>25</td>\n",
       "      <td>2,535</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name matches points rating\n",
       "0     Australia      21  3,342  172\\n\n",
       "1       England      28  3,098    119\n",
       "2  South Africa      26  2,820    119\n",
       "3         India      27  2,553    104\n",
       "4   New Zealand      25  2,535    102"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6=pd.DataFrame()\n",
    "data6['name']= women_team\n",
    "data6['matches']= team_wm_match\n",
    "data6['points']= women_team_point\n",
    "data6['rating']= team_wm_rating\n",
    "data6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 7: Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and\n",
    "make data framei) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "a271d7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page7 = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "page7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "e3108ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Elon Musk, who co-founded firm behind ChatGPT, warns A.I. is 'one of the biggest risks' to civilization\",\n",
       " \"EU announces new Russia sanctions package; Ukrainian children sent to Russian 're-education' camps, study says\",\n",
       " 'This fund manager says a bull market might be on the horizon — and names her top stock picks',\n",
       " 'Dow sheds more than 100 points as investors weigh retail sales, inflation data: Live updates',\n",
       " 'Early Deliveroo investor Hoxton Ventures is set to lose one of its founding partners',\n",
       " \"BofA says these global stocks can weather a choppy market — and are 'inexpensive'\",\n",
       " 'Apple patent adds to hype around foldable device from the iPhone maker',\n",
       " 'UK inflation rate dips for third straight month to hit 10.1%',\n",
       " 'Shut out from their top destinations, Chinese travelers are turning to other places',\n",
       " 'Death toll in Turkey and Syria earthquake tops 41,000 as UN says rescue phase is coming to a close',\n",
       " \"Barclays says buy Tesla shares, sees 30% rally in the 'clear leader' of the electric transition\",\n",
       " \"Indian tycoon Gautam Adani dismisses market volatility as 'temporary' \"]"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup7 = BeautifulSoup(page7.content)\n",
    "soup7 = BeautifulSoup(page7.content, \"html.parser\")\n",
    "headline = soup7.find_all('div', class_=\"RiverHeadline-headline RiverHeadline-hasThumbnail\")\n",
    "headlines = []\n",
    "for head in headline:\n",
    "    headlines.append(head.get_text())\n",
    "headlines1=headlines[0:12]\n",
    "headlines1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "b2901ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25 min ago',\n",
       " '25 min ago',\n",
       " '37 min ago',\n",
       " '37 min ago',\n",
       " '8 min ago',\n",
       " '8 min ago',\n",
       " '2 hours ago',\n",
       " '2 hours ago',\n",
       " '2 hours ago',\n",
       " '2 hours ago',\n",
       " '5 hours ago',\n",
       " '5 hours ago']"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = soup7.find_all('span', class_=\"RiverByline-datePublished\")\n",
    "time = []\n",
    "for tim in times:\n",
    "    time.append(tim.get_text())\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "15868263",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsLink = []  ## creating empty list\n",
    "\n",
    "\n",
    "for i in soup7.find_all(\"div\",class_=\"LatestNews-container\"):\n",
    "\n",
    "     newsLink.append(i.find(\"a\",class_=\"LatestNews-headline\").get(\"href\"))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "1115c2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk, who co-founded firm behind ChatGPT,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EU announces new Russia sanctions package; Ukr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This fund manager says a bull market might be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dow sheds more than 100 points as investors we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Early Deliveroo investor Hoxton Ventures is se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Headlines\n",
       "0  Elon Musk, who co-founded firm behind ChatGPT,...\n",
       "1  EU announces new Russia sanctions package; Ukr...\n",
       "2  This fund manager says a bull market might be ...\n",
       "3  Dow sheds more than 100 points as investors we...\n",
       "4  Early Deliveroo investor Hoxton Ventures is se..."
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data7=pd.DataFrame()\n",
    "data7['Headlines']=headlines\n",
    "\n",
    "data7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c4215",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 8: Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details and make data framei) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "cc0c1048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page8 = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "page8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "008d2860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reward is enough',\n",
       " 'Making sense of raw input',\n",
       " 'Law and logic: A review from an argumentation perspective',\n",
       " 'Creativity and artificial intelligence',\n",
       " 'Artificial cognition for social human–robot interaction: An implementation',\n",
       " 'Explanation in artificial intelligence: Insights from the social sciences',\n",
       " 'Making sense of sensory input',\n",
       " 'Conflict-based search for optimal multi-agent pathfinding',\n",
       " 'Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning',\n",
       " 'The Hanabi challenge: A new frontier for AI research',\n",
       " 'Evaluating XAI: A comparison of rule-based and example-based explanations',\n",
       " 'Argumentation in artificial intelligence',\n",
       " 'Algorithms for computing strategies in two-player simultaneous move games',\n",
       " 'Multiple object tracking: A literature review',\n",
       " 'Selection of relevant features and examples in machine learning',\n",
       " 'A survey of inverse reinforcement learning: Challenges, methods and progress',\n",
       " 'Explaining individual predictions when features are dependent: More accurate approximations to Shapley values',\n",
       " 'A review of possible effects of cognitive biases on interpretation of rule-based machine learning models',\n",
       " 'Integrating social power into the decision-making of cognitive agents',\n",
       " \"“That's (not) the output I expected!” On the role of end user expectations in creating explanations of AI systems\",\n",
       " 'Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies',\n",
       " 'Algorithm runtime prediction: Methods & evaluation',\n",
       " 'Wrappers for feature subset selection',\n",
       " 'Commonsense visual sensemaking for autonomous driving – On generalised neurosymbolic online abduction integrating vision and semantics',\n",
       " 'Quantum computation, quantum theory and AI']"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup8 = BeautifulSoup(page8.content)\n",
    "soup8 = BeautifulSoup(page8.content, \"html.parser\")\n",
    "article = soup8.find_all('h2', class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\")\n",
    "articles = []\n",
    "for arti in article:\n",
    "    articles.append(arti.get_text())\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "0de5cc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Silver, David, Singh, Satinder, Precup, Doina, Sutton, Richard S. ',\n",
       " 'Evans, Richard, Bošnjak, Matko and 5 more',\n",
       " 'Prakken, Henry, Sartor, Giovanni ',\n",
       " 'Boden, Margaret A. ',\n",
       " 'Lemaignan, Séverin, Warnier, Mathieu and 3 more',\n",
       " 'Miller, Tim ',\n",
       " 'Evans, Richard, Hernández-Orallo, José and 3 more',\n",
       " 'Sharon, Guni, Stern, Roni, Felner, Ariel, Sturtevant, Nathan R. ',\n",
       " 'Sutton, Richard S., Precup, Doina, Singh, Satinder ',\n",
       " 'Bard, Nolan, Foerster, Jakob N. and 13 more',\n",
       " 'van der Waa, Jasper, Nieuwburg, Elisabeth, Cremers, Anita, Neerincx, Mark ',\n",
       " 'Bench-Capon, T.J.M., Dunne, Paul E. ',\n",
       " 'Bošanský, Branislav, Lisý, Viliam and 3 more',\n",
       " 'Luo, Wenhan, Xing, Junliang and 4 more',\n",
       " 'Blum, Avrim L., Langley, Pat ',\n",
       " 'Arora, Saurabh, Doshi, Prashant ',\n",
       " 'Aas, Kjersti, Jullum, Martin, Løland, Anders ',\n",
       " 'Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Johannes ',\n",
       " 'Pereira, Gonçalo, Prada, Rui, Santos, Pedro A. ',\n",
       " 'Riveiro, Maria, Thill, Serge ',\n",
       " 'Kenny, Eoin M., Ford, Courtney, Quinn, Molly, Keane, Mark T. ',\n",
       " 'Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyton-Brown, Kevin ',\n",
       " 'Kohavi, Ron, John, George H. ',\n",
       " 'Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srikrishna ',\n",
       " 'Ying, Mingsheng ']"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = soup8.find_all('span', class_=\"sc-1w3fpd7-0 dnCnAO\")\n",
    "authors = []\n",
    "for auth in author:\n",
    "    authors.append(auth.get_text())\n",
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "767d0b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['October 2021',\n",
       " 'October 2021',\n",
       " 'October 2015',\n",
       " 'August 1998',\n",
       " 'June 2017',\n",
       " 'February 2019',\n",
       " 'April 2021',\n",
       " 'February 2015',\n",
       " 'August 1999',\n",
       " 'March 2020',\n",
       " 'February 2021',\n",
       " 'October 2007',\n",
       " 'August 2016',\n",
       " 'April 2021',\n",
       " 'December 1997',\n",
       " 'August 2021',\n",
       " 'September 2021',\n",
       " 'June 2021',\n",
       " 'December 2016',\n",
       " 'September 2021',\n",
       " 'May 2021',\n",
       " 'January 2014',\n",
       " 'December 1997',\n",
       " 'October 2021',\n",
       " 'February 2010']"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = soup8.find_all('span', class_=\"sc-1thf9ly-2 dvggWt\")\n",
    "dates = []\n",
    "for dat in date:\n",
    "    dates.append(dat.get_text())\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "930920e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Published Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Paper Title  \\\n",
       "0                                   Reward is enough   \n",
       "1                          Making sense of raw input   \n",
       "2  Law and logic: A review from an argumentation ...   \n",
       "3             Creativity and artificial intelligence   \n",
       "4  Artificial cognition for social human–robot in...   \n",
       "\n",
       "                                              Author Published Date  \n",
       "0  Silver, David, Singh, Satinder, Precup, Doina,...   October 2021  \n",
       "1          Evans, Richard, Bošnjak, Matko and 5 more   October 2021  \n",
       "2                  Prakken, Henry, Sartor, Giovanni    October 2015  \n",
       "3                                Boden, Margaret A.     August 1998  \n",
       "4    Lemaignan, Séverin, Warnier, Mathieu and 3 more      June 2017  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data8 = pd.DataFrame()\n",
    "data8['Paper Title']=articles\n",
    "data8['Author']=authors\n",
    "data8['Published Date']=dates\n",
    "data8.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
